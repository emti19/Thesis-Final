{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "mount_file_id": "1ul6s8R-PvxQsD5UqyvSqpL3YVF6IlF2_",
      "authorship_tag": "ABX9TyPGmUvPcitmpwbb3aX85n0W",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/emti19/Thesis-Final/blob/main/Final_Code(Deep_Learning%2C_NLP).ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "pfhjEatrCGa9",
        "outputId": "7bc71c97-61fe-473d-ad51-d04dfb69b64e"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "['উপরের', 'ধরনের', 'অ', 'ইউক্লিডীয়', 'জ্যামিতির', 'বিস্তারিত', 'বিবরণ', 'জটিল', 'দুটিকেই', 'সহজ', 'মডেলের', 'দেখানো', 'সম্ভব', 'বলিয়াই', 'লোবাচেভ্', 'স্কি', 'জ্যামিতিতে', 'সময়', 'অধিবৃত্তীয়', 'জ্যামিতিও', 'হয়।']\n",
            "['উল্লেখিত', 'রকমের', 'অ', 'ইউক্লিডীয়', 'জ্যামিতির', 'বিস্তীর্ণ', 'বিবরণ', 'ভালোই', 'জটিল', 'উভয়কে', 'সরল', 'মডেলের', 'দেখানো', 'সম্ভব', 'লোবাচেভ্', 'স্কি', 'জ্যামিতিতে', 'অনেকসময়', 'অধিবৃত্তীয়', 'জ্যামিতিও', 'বলে।']\n",
            "{'জ্যামিতিও', 'বিস্তারিত', 'অ', 'সম্ভব', 'বিবরণ', 'জ্যামিতিতে', 'উপরের', 'জ্যামিতির', 'সহজ', 'লোবাচেভ্', 'ইউক্লিডীয়', 'ধরনের', 'হয়।', 'বলিয়াই', 'দুটিকেই', 'স্কি', 'জটিল', 'অধিবৃত্তীয়', 'মডেলের', 'সময়', 'দেখানো'}\n",
            "{'উল্লেখিত', 'জ্যামিতিও', 'বিস্তারিত', 'অ', 'সম্ভব', 'বলে।', 'বিবরণ', 'জ্যামিতিতে', 'উপরের', 'জ্যামিতির', 'সহজ', 'লোবাচেভ্', 'ভালোই', 'ইউক্লিডীয়', 'ধরনের', 'হয়।', 'বিস্তীর্ণ', 'রকমের', 'উভয়কে', 'বলিয়াই', 'দুটিকেই', 'অনেকসময়', 'স্কি', 'সরল', 'জটিল', 'অধিবৃত্তীয়', 'মডেলের', 'সময়', 'দেখানো'}\n",
            "13\n",
            "61.90 %\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[nltk_data] Downloading package punkt to /root/nltk_data...\n",
            "[nltk_data]   Package punkt is already up-to-date!\n"
          ]
        }
      ],
      "source": [
        "import nltk\n",
        "import pandas as pd\n",
        "################# bltk is nltk alternative for Bangla Language\n",
        "from bltk.langtools import remove_stopwords\n",
        "from nltk.tokenize import word_tokenize\n",
        "nltk.download('punkt')\n",
        "\n",
        "\n",
        "stopWords = pd.read_csv('/content/drive/MyDrive/Colab Notebooks/Stopwords.csv')\n",
        "\n",
        "original = \"উপরের দুই ধরনের অ ইউক্লিডীয় জ্যামিতির বিস্তারিত বিবরণ বেশ জটিল তবে দুটিকেই সহজ মডেলের মাধ্যমে দেখানো সম্ভব বলিয়াই লোবাচেভ্ স্কি জ্যামিতিতে যাকে অনেক সময় অধিবৃত্তীয় জ্যামিতিও বলা হয়।\"\n",
        "suspicious =\"উল্লেখিত দুই রকমের অ ইউক্লিডীয় জ্যামিতির বিস্তীর্ণ বিবরণ ভালোই জটিল হলেও উভয়কে সরল মডেলের মাধ্যমে দেখানো সম্ভব বলে লোবাচেভ্ স্কি জ্যামিতিতে একে অনেকসময় অধিবৃত্তীয় জ্যামিতিও বলে।\"\n",
        "\n",
        "################# work tokenization\n",
        "tokened_words1 = word_tokenize(original)\n",
        "tokened_words2 = word_tokenize(suspicious)\n",
        "\n",
        "################# bangla encoding\n",
        "def to_encode(bangla_word):\n",
        "  return bangla_word.encode('utf-8')\n",
        "\n",
        "def to_decode(bangla_word):\n",
        "  return bangla_word.decode('utf-8')\n",
        "\n",
        "set_stop = set(stopWords['words'].map(to_encode))\n",
        "\n",
        "################# removing stopwords\n",
        "originalCleanText  = remove_stopwords(tokened_words1, level='moderate')\n",
        "suspiciousCleanText  = remove_stopwords(tokened_words2, level='moderate')\n",
        "\n",
        "X_set = {w for w in originalCleanText if not w in set_stop}\n",
        "Y_set = {w for w in suspiciousCleanText if not w in set_stop}\n",
        "\n",
        "print(X_set)\n",
        "################# applying word2vec model\n",
        "l1 =[];l2 =[]\n",
        "rvector = X_set.union(Y_set)\n",
        "for w in rvector:\n",
        "    if w in X_set: l1.append(1)\n",
        "    else: l1.append(0)\n",
        "    if w in Y_set: l2.append(1)\n",
        "    else: l2.append(0)\n",
        "c = 0\n",
        "print(rvector)\n",
        "for i in range(len(rvector)):\n",
        "        c+= l1[i]*l2[i]\n",
        "# print(l1)\n",
        "# print(l2)\n",
        "print(c)\n",
        "################# cosine similarity calculation\n",
        "cosine_similarity = c / float((sum(l1)*sum(l2))**0.5)\n",
        "plagiarism = cosine_similarity*100\n",
        "################# and the final output1: Cosine Similarity\n",
        "print(\"%.2f\" % plagiarism,\"%\")\n"
      ]
    }
  ]
}